[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "I am Xinyu(Yuki) Shen\nI am an aspiring data scientist passionate about uncovering insights through statistical modeling and machine learning. I am currently an undergraduate at the University of Florida, pursuing a double major in Data Science and Economics with a minor in Mathematics.\nMy work spans academic research, analytics competitions, and independent projectsâ€”each deepening my experience in programming with Python and R, and using tools like R Shiny, SAS, and Excel to explore and visualize complex data. I am particularly drawn to applying data science methods to solve real-world problems, whether through predictive modeling, exploratory analysis, or interactive dashboards.\nI am also committed to producing clear, reproducible work and enjoy using tools like RMarkdown and Quarto to document and share my analyses with clarity and transparency.\nIf I could describe myself using three emojis, I would choose: ğŸ“ŠğŸ§ â˜•"
  },
  {
    "objectID": "models/datasets.html",
    "href": "models/datasets.html",
    "title": "Data and Research Question",
    "section": "",
    "text": "The Youth Risk Behavior Survey (YRBS) is a national survey that monitors health-related behaviors among high school students, including weapon carrying and associated risk factors.\n\n\n\nSource: Centers for Disease Control and Prevention (CDC)\nYear: 2023\nTarget Population: High school students\nSample Size: Approximately 19,000 students nationwide\n\n\n\n\nHow do logistic regression, lasso, k-nearest neighbors, and tree-based models compare in predicting school-based weapon carrying among adolescents based on risk and protective factors?\n\n\n\nThe dataset includes information on various health-related behaviors:\n\nOutcome\n\nWeapon Carrying (Carried a weapon on school property)\n\nPredictors\n\nTraumatic experiences\nSchool Safety Perceptions\nBullying Experiences\nFamily Support\nSocial Media Use\nPeer Relationships\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(dissertationData)\nlibrary(here)\ndata(clean_yrbs_2023)\n# Add your data preprocessing code here\n\n\n\n\nWe will do it in classâ€¦\n\n\n\n\n# This is an example of how to create a dataset for a model.\n# You can use this as a template to create your own dataset.\n\n\nanalysis_data &lt;- clean_yrbs_2023 %&gt;%\n    select(\n        WeaponCarryingSchool, AttackedInNeighborhood, Bullying,\n        SexualAbuseByOlderPerson, ParentalPhysicalAbuse, ParentSubstanceUse,\n        ParentIncarceration, SchoolConnectedness, ParentalMonitoring,\n        UnfairDisciplineAtSchool, Homelessness\n    ) |&gt;\n    filter(!is.na(WeaponCarryingSchool)) %&gt;%\n    mutate(across(\n        c(\n            ParentSubstanceUse, ParentIncarceration, SchoolConnectedness,\n            ParentalMonitoring, UnfairDisciplineAtSchool\n        ),\n        ~ as.numeric(.x) - 1\n    )) %&gt;%\n    mutate(across(\n        c(\n            ParentSubstanceUse, ParentIncarceration, SchoolConnectedness,\n            ParentalMonitoring, UnfairDisciplineAtSchool\n        ),\n        ~ factor(.x)\n    ))\n\n\n\n\n\n\n\n\nanalysis_folds &lt;- vfold_cv(analysis_train,\n    v = 5\n)\nanalysis_folds"
  },
  {
    "objectID": "models/datasets.html#youth-risk-behavior-survey-2023",
    "href": "models/datasets.html#youth-risk-behavior-survey-2023",
    "title": "Data and Research Question",
    "section": "",
    "text": "The Youth Risk Behavior Survey (YRBS) is a national survey that monitors health-related behaviors among high school students, including weapon carrying and associated risk factors.\n\n\n\nSource: Centers for Disease Control and Prevention (CDC)\nYear: 2023\nTarget Population: High school students\nSample Size: Approximately 19,000 students nationwide\n\n\n\n\nHow do logistic regression, lasso, k-nearest neighbors, and tree-based models compare in predicting school-based weapon carrying among adolescents based on risk and protective factors?\n\n\n\nThe dataset includes information on various health-related behaviors:\n\nOutcome\n\nWeapon Carrying (Carried a weapon on school property)\n\nPredictors\n\nTraumatic experiences\nSchool Safety Perceptions\nBullying Experiences\nFamily Support\nSocial Media Use\nPeer Relationships\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(dissertationData)\nlibrary(here)\ndata(clean_yrbs_2023)\n# Add your data preprocessing code here\n\n\n\n\nWe will do it in classâ€¦\n\n\n\n\n# This is an example of how to create a dataset for a model.\n# You can use this as a template to create your own dataset.\n\n\nanalysis_data &lt;- clean_yrbs_2023 %&gt;%\n    select(\n        WeaponCarryingSchool, AttackedInNeighborhood, Bullying,\n        SexualAbuseByOlderPerson, ParentalPhysicalAbuse, ParentSubstanceUse,\n        ParentIncarceration, SchoolConnectedness, ParentalMonitoring,\n        UnfairDisciplineAtSchool, Homelessness\n    ) |&gt;\n    filter(!is.na(WeaponCarryingSchool)) %&gt;%\n    mutate(across(\n        c(\n            ParentSubstanceUse, ParentIncarceration, SchoolConnectedness,\n            ParentalMonitoring, UnfairDisciplineAtSchool\n        ),\n        ~ as.numeric(.x) - 1\n    )) %&gt;%\n    mutate(across(\n        c(\n            ParentSubstanceUse, ParentIncarceration, SchoolConnectedness,\n            ParentalMonitoring, UnfairDisciplineAtSchool\n        ),\n        ~ factor(.x)\n    ))\n\n\n\n\n\n\n\n\nanalysis_folds &lt;- vfold_cv(analysis_train,\n    v = 5\n)\nanalysis_folds"
  },
  {
    "objectID": "models/lasso.html",
    "href": "models/lasso.html",
    "title": "Lasso Regression",
    "section": "",
    "text": "Lasso regression is a statistical model that combines linear/logistic regression with L1 regularization to perform both variable selection and regularization. The term â€œLassoâ€ stands for â€œLeast Absolute Shrinkage and Selection Operator.â€ This method is particularly useful when dealing with datasets that have many predictors, as it helps to: - Reduce overfitting by penalizing large coefficients - Perform automatic feature selection by shrinking some coefficients to exactly zero - Handle multicollinearity by selecting only one variable from a group of highly correlated predictors\nIn this analysis, weâ€™ll use Lasso regression to predict weapon carrying behavior in schools, demonstrating how this method can help identify the most important predictors while maintaining model interpretability."
  },
  {
    "objectID": "models/lasso.html#setting-up-the-environment",
    "href": "models/lasso.html#setting-up-the-environment",
    "title": "Lasso Regression",
    "section": "Setting Up the Environment",
    "text": "Setting Up the Environment\nFirst, we need to load the necessary packages for our analysis. Weâ€™ll use tidymodels for modeling, tidyverse for data manipulation, and here for consistent file paths.\n\nlibrary(here)\nlibrary(tidymodels)\nlibrary(tidyverse)"
  },
  {
    "objectID": "models/lasso.html#loading-the-data",
    "href": "models/lasso.html#loading-the-data",
    "title": "Lasso Regression",
    "section": "Loading the Data",
    "text": "Loading the Data\nWeâ€™ll work with pre-processed data sets that have been split into training and test sets, along with cross-validation folds. These files are stored in the processed_data directory.\n\nanalysis_data &lt;- readRDS(here(\"models\", \"data\", \"analysis_data.rds\"))\nanalysis_train &lt;- readRDS(here(\"models\", \"data\", \"analysis_train.rds\"))\nanalysis_test &lt;- readRDS(here(\"models\",\"data\", \"analysis_test.rds\"))\nanalysis_folds &lt;- readRDS(here(\"models\", \"data\", \"analysis_folds.rds\"))"
  },
  {
    "objectID": "models/lasso.html#data-preprocessing",
    "href": "models/lasso.html#data-preprocessing",
    "title": "Lasso Regression",
    "section": "Data Preprocessing",
    "text": "Data Preprocessing\nBefore fitting our model, we need to preprocess the data. Weâ€™ll create a recipe that: - Imputes missing values in categorical variables using the mode - Imputes missing values in numeric variables using the mean - Removes predictors with zero variance - Removes highly correlated predictors (correlation threshold = 0.7) - Creates dummy variables for categorical predictors\n\nweapon_carry_recipe &lt;- \n  recipe(formula = WeaponCarryingSchool ~ ., data = analysis_train) |&gt;\n  step_impute_mode(all_nominal_predictors()) |&gt;\n  step_impute_mean(all_numeric_predictors()) |&gt;\n  step_zv(all_predictors()) |&gt; \n  step_corr(all_numeric_predictors(), threshold = 0.7) %&gt;% \n  step_dummy(all_nominal_predictors())\n\nweapon_carry_recipe\n\n\n\n\nâ”€â”€ Recipe â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n\n\n\n\nâ”€â”€ Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor: 10\n\n\n\n\n\nâ”€â”€ Operations \n\n\nâ€¢ Mode imputation for: all_nominal_predictors()\n\n\nâ€¢ Mean imputation for: all_numeric_predictors()\n\n\nâ€¢ Zero variance filter on: all_predictors()\n\n\nâ€¢ Correlation filter on: all_numeric_predictors()\n\n\nâ€¢ Dummy variables from: all_nominal_predictors()\n\n\nLetâ€™s apply our recipe to transform the data according to these preprocessing steps.\n\nweapon_carry_recipe %&gt;% \n  prep() %&gt;% \n  bake(new_data = analysis_data) \n\n# A tibble: 19,595 Ã— 11\n   WeaponCarryingSchool AttackedInNeighborhood_X1 Bullying_X1\n   &lt;fct&gt;                                    &lt;dbl&gt;       &lt;dbl&gt;\n 1 0                                            0           0\n 2 0                                            0           1\n 3 0                                            0           0\n 4 0                                            0           0\n 5 0                                            0           0\n 6 0                                            1           0\n 7 0                                            0           0\n 8 0                                            0           0\n 9 0                                            0           0\n10 0                                            0           0\n# â„¹ 19,585 more rows\n# â„¹ 8 more variables: SexualAbuseByOlderPerson_X1 &lt;dbl&gt;,\n#   ParentalPhysicalAbuse_X1 &lt;dbl&gt;, ParentSubstanceUse_X1 &lt;dbl&gt;,\n#   ParentIncarceration_X1 &lt;dbl&gt;, SchoolConnectedness_X1 &lt;dbl&gt;,\n#   ParentalMonitoring_X1 &lt;dbl&gt;, UnfairDisciplineAtSchool_X1 &lt;dbl&gt;,\n#   Homelessness_X1 &lt;dbl&gt;"
  },
  {
    "objectID": "models/lasso.html#model-specification",
    "href": "models/lasso.html#model-specification",
    "title": "Lasso Regression",
    "section": "Model Specification",
    "text": "Model Specification\nWeâ€™ll use a logistic regression model with Lasso regularization. The Lasso (Least Absolute Shrinkage and Selection Operator) helps with feature selection by penalizing the absolute size of coefficients. We set mixture = 1 to specify a pure Lasso model, and weâ€™ll tune the penalty parameter to find the optimal level of regularization.\n\nweapon_carry_spec &lt;-\n  logistic_reg(penalty = tune(), \n               mixture = 1) |&gt; \n  set_engine('glmnet')\n\nweapon_carry_spec\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet"
  },
  {
    "objectID": "models/lasso.html#creating-the-workflow",
    "href": "models/lasso.html#creating-the-workflow",
    "title": "Lasso Regression",
    "section": "Creating the Workflow",
    "text": "Creating the Workflow\nWeâ€™ll combine our recipe and model specification into a single workflow. This ensures that all preprocessing steps are properly applied during both training and prediction.\n\nweapon_carry_workflow &lt;-\n  workflow() |&gt;\n  add_recipe(weapon_carry_recipe) |&gt;\n  add_model(weapon_carry_spec)\n\nweapon_carry_workflow\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: logistic_reg()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n5 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_zv()\nâ€¢ step_corr()\nâ€¢ step_dummy()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet"
  },
  {
    "objectID": "models/lasso.html#model-tuning",
    "href": "models/lasso.html#model-tuning",
    "title": "Lasso Regression",
    "section": "Model Tuning",
    "text": "Model Tuning\nTo find the optimal penalty value, weâ€™ll create a grid of potential values to test. Weâ€™ll use 50 different penalty values, evenly spaced on a logarithmic scale.\n\nlambda_grid &lt;- grid_regular(penalty(), levels = 50)\nlambda_grid\n\n# A tibble: 50 Ã— 1\n    penalty\n      &lt;dbl&gt;\n 1 1   e-10\n 2 1.60e-10\n 3 2.56e-10\n 4 4.09e-10\n 5 6.55e-10\n 6 1.05e- 9\n 7 1.68e- 9\n 8 2.68e- 9\n 9 4.29e- 9\n10 6.87e- 9\n# â„¹ 40 more rows\n\n\nNow, weâ€™ll perform cross-validation to find the best penalty value. This process is time-consuming, so weâ€™ll save the results for future use.\n\nset.seed(2023)\n\nlasso_tune &lt;- \n  tune_grid(\n  object = weapon_carry_workflow, \n  resamples = analysis_folds,\n  grid = lambda_grid, \n  control = control_resamples(event_level = \"second\")\n)\n\nLetâ€™s examine the performance metrics for different penalty values.\n\nlasso_tune %&gt;% \n  collect_metrics()\n\n# A tibble: 150 Ã— 7\n    penalty .metric     .estimator  mean     n std_err .config              \n      &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1 1   e-10 accuracy    binary     0.957     5 0.00158 Preprocessor1_Model01\n 2 1   e-10 brier_class binary     0.881     5 0.00160 Preprocessor1_Model01\n 3 1   e-10 roc_auc     binary     0.688     5 0.00742 Preprocessor1_Model01\n 4 1.60e-10 accuracy    binary     0.957     5 0.00158 Preprocessor1_Model02\n 5 1.60e-10 brier_class binary     0.881     5 0.00160 Preprocessor1_Model02\n 6 1.60e-10 roc_auc     binary     0.688     5 0.00742 Preprocessor1_Model02\n 7 2.56e-10 accuracy    binary     0.957     5 0.00158 Preprocessor1_Model03\n 8 2.56e-10 brier_class binary     0.881     5 0.00160 Preprocessor1_Model03\n 9 2.56e-10 roc_auc     binary     0.688     5 0.00742 Preprocessor1_Model03\n10 4.09e-10 accuracy    binary     0.957     5 0.00158 Preprocessor1_Model04\n# â„¹ 140 more rows\n\n\nWe can visualize how the modelâ€™s performance changes with different penalty values.\n\nautoplot(lasso_tune)"
  },
  {
    "objectID": "models/lasso.html#selecting-the-best-model",
    "href": "models/lasso.html#selecting-the-best-model",
    "title": "Lasso Regression",
    "section": "Selecting the Best Model",
    "text": "Selecting the Best Model\nWeâ€™ll select the best model based on the ROC AUC metric, which measures the modelâ€™s ability to distinguish between classes.\n\nbest &lt;- lasso_tune |&gt; \n  select_best(metric =\"roc_auc\")\n\nbest\n\n# A tibble: 1 Ã— 2\n   penalty .config              \n     &lt;dbl&gt; &lt;chr&gt;                \n1 0.000339 Preprocessor1_Model33\n\n\nNow weâ€™ll create our final workflow with the best penalty value.\n\nfinal_wf &lt;- finalize_workflow(weapon_carry_workflow, best)\n\nfinal_wf\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: logistic_reg()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n5 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_zv()\nâ€¢ step_corr()\nâ€¢ step_dummy()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = 0.000339322177189533\n  mixture = 1\n\nComputational engine: glmnet"
  },
  {
    "objectID": "models/lasso.html#fitting-the-final-model",
    "href": "models/lasso.html#fitting-the-final-model",
    "title": "Lasso Regression",
    "section": "Fitting the Final Model",
    "text": "Fitting the Final Model\nWeâ€™ll fit our final model on the training data. This process is also time-consuming, so weâ€™ll save the results.\n\nweapon_fit &lt;- \n  fit(final_wf, data = analysis_train)\n\nweapon_fit"
  },
  {
    "objectID": "models/lasso.html#model-evaluation",
    "href": "models/lasso.html#model-evaluation",
    "title": "Lasso Regression",
    "section": "Model Evaluation",
    "text": "Model Evaluation\nLetâ€™s examine the modelâ€™s predictions on the training data.\n\nweapon_pred &lt;- \n  augment(weapon_fit, analysis_train) |&gt; \n  select(WeaponCarryingSchool, .pred_class, .pred_1, .pred_0)\n\nweapon_pred\n\n# A tibble: 14,696 Ã— 4\n   WeaponCarryingSchool .pred_class .pred_1 .pred_0\n   &lt;fct&gt;                &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;\n 1 0                    0            0.0368   0.963\n 2 0                    0            0.0410   0.959\n 3 0                    0            0.0253   0.975\n 4 0                    0            0.0325   0.968\n 5 0                    0            0.125    0.875\n 6 0                    0            0.0368   0.963\n 7 0                    0            0.0208   0.979\n 8 0                    0            0.0208   0.979\n 9 0                    0            0.0458   0.954\n10 0                    0            0.0529   0.947\n# â„¹ 14,686 more rows\n\n\nWe can visualize the modelâ€™s performance using an ROC curve.\n\nroc_plot_training &lt;- \n  weapon_pred |&gt; \n  roc_curve(truth = WeaponCarryingSchool, .pred_1, event_level = \"second\") |&gt; \n  autoplot()\n\nroc_plot_training \n\n\n\n\n\n\n\n\nLetâ€™s look at the model coefficients to understand which predictors are most important.\n\nweapon_fit |&gt; \n  extract_fit_parsnip() |&gt; \n  tidy()\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoaded glmnet 4.1-8\n\n\n# A tibble: 11 Ã— 3\n   term                        estimate  penalty\n   &lt;chr&gt;                          &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)                  -3.29   0.000339\n 2 AttackedInNeighborhood_X1     0.739  0.000339\n 3 Bullying_X1                   0.472  0.000339\n 4 SexualAbuseByOlderPerson_X1   0.455  0.000339\n 5 ParentalPhysicalAbuse_X1      0.708  0.000339\n 6 ParentSubstanceUse_X1        -0.132  0.000339\n 7 ParentIncarceration_X1        0.0271 0.000339\n 8 SchoolConnectedness_X1       -0.226  0.000339\n 9 ParentalMonitoring_X1         0.584  0.000339\n10 UnfairDisciplineAtSchool_X1  -0.229  0.000339\n11 Homelessness_X1               1.17   0.000339"
  },
  {
    "objectID": "models/lasso.html#cross-validation-results",
    "href": "models/lasso.html#cross-validation-results",
    "title": "Lasso Regression",
    "section": "Cross-Validation Results",
    "text": "Cross-Validation Results\nWeâ€™ll fit the model on each cross-validation fold to get a more robust estimate of its performance.\n\nweapon_fit_resamples &lt;- \n  fit_resamples(final_wf, resamples = analysis_folds)\n\nweapon_fit_resamples\n\nLetâ€™s examine the cross-validation metrics.\n\ncollect_metrics(weapon_fit_resamples)\n\n# A tibble: 3 Ã— 6\n  .metric     .estimator   mean     n std_err .config             \n  &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary     0.957      5 0.00158 Preprocessor1_Model1\n2 brier_class binary     0.0399     5 0.00128 Preprocessor1_Model1\n3 roc_auc     binary     0.688      5 0.00737 Preprocessor1_Model1"
  },
  {
    "objectID": "models/lasso.html#variable-importance",
    "href": "models/lasso.html#variable-importance",
    "title": "Lasso Regression",
    "section": "Variable Importance",
    "text": "Variable Importance\nFinally, letâ€™s create a variable importance plot to identify the most influential predictors in our model.\n\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nweapon_fit |&gt; \n  extract_fit_engine() |&gt; \n  vip()"
  },
  {
    "objectID": "models/lasso.html#results-and-interpretation",
    "href": "models/lasso.html#results-and-interpretation",
    "title": "Lasso Regression",
    "section": "Results and Interpretation",
    "text": "Results and Interpretation\n[Add your interpretation of the results here]"
  },
  {
    "objectID": "models/logistic.html",
    "href": "models/logistic.html",
    "title": "Logistic Regression",
    "section": "",
    "text": "Logistic regression is a statistical model thatâ€¦\n\nModel Overview\nLogistic regression is used when the dependent variable is binary (0/1, Yes/No, True/False). The model estimates the probability of the dependent variable being 1 given the independent variables.\n\n\nImplementation\n\nlibrary(tidymodels)\nlibrary(tidyverse)\nlibrary(dissertationData)\nlibrary(here)\n\n# Load and prepare the YRBS 2023 dataset\n\n\n\nLoad the data\n\nanalysis_data &lt;- readRDS(here(\"models\", \"data\", \"analysis_data.rds\"))\nanalysis_train &lt;- readRDS(here(\"models\", \"data\", \"analysis_train.rds\"))\nanalysis_test &lt;- readRDS(here(\"models\", \"data\", \"analysis_test.rds\"))\nanalysis_folds &lt;- readRDS(here(\"models\", \"data\", \"analysis_folds.rds\"))\n\n\n\nRecipe\n\nweapon_carry_recipe &lt;- \n  recipe(formula = WeaponCarryingSchool ~ ., data = analysis_data) |&gt;\n  step_impute_mode(all_nominal_predictors()) |&gt;\n  step_impute_mean(all_numeric_predictors()) |&gt;\n  step_zv(all_predictors()) |&gt; \n  step_corr(all_numeric_predictors(), threshold = 0.7) \n\nweapon_carry_recipe\n\n\n\n\nâ”€â”€ Recipe â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n\n\n\n\nâ”€â”€ Inputs \n\n\nNumber of variables by role\n\n\noutcome:    1\npredictor: 10\n\n\n\n\n\nâ”€â”€ Operations \n\n\nâ€¢ Mode imputation for: all_nominal_predictors()\n\n\nâ€¢ Mean imputation for: all_numeric_predictors()\n\n\nâ€¢ Zero variance filter on: all_predictors()\n\n\nâ€¢ Correlation filter on: all_numeric_predictors()\n\n\n\n\nBake\n\nrec &lt;- weapon_carry_recipe %&gt;% \n  prep() %&gt;% \n  bake(new_data = analysis_data) %&gt;% glimpse()\n\nRows: 19,595\nColumns: 11\n$ AttackedInNeighborhood   &lt;fct&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, â€¦\n$ Bullying                 &lt;fct&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, â€¦\n$ SexualAbuseByOlderPerson &lt;fct&gt; 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, â€¦\n$ ParentalPhysicalAbuse    &lt;fct&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, â€¦\n$ ParentSubstanceUse       &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, â€¦\n$ ParentIncarceration      &lt;fct&gt; 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, â€¦\n$ SchoolConnectedness      &lt;fct&gt; 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, â€¦\n$ ParentalMonitoring       &lt;fct&gt; 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, â€¦\n$ UnfairDisciplineAtSchool &lt;fct&gt; 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, â€¦\n$ Homelessness             &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, â€¦\n$ WeaponCarryingSchool     &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, â€¦\n\n\n\n\nModel Specification\n\nweapon_carry_spec &lt;- \n  logistic_reg() %&gt;% \n  set_mode(\"classification\") %&gt;% \n  set_engine(\"glm\") \n\nweapon_carry_spec\n\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n\nWorkflow\n\nweapon_carry_workflow &lt;- workflow() %&gt;%\n  add_recipe(weapon_carry_recipe) %&gt;%\n  add_model(weapon_carry_spec)\n\n\nweapon_carry_workflow\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: logistic_reg()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n4 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_zv()\nâ€¢ step_corr()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\nmod_1 &lt;- \n  fit(weapon_carry_workflow, data = analysis_train) \n\nmod_1\n\nâ•â• Workflow [trained] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: logistic_reg()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n4 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_zv()\nâ€¢ step_corr()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nCall:  stats::glm(formula = ..y ~ ., family = stats::binomial, data = data)\n\nCoefficients:\n              (Intercept)    AttackedInNeighborhood1  \n                 -3.29938                    0.74950  \n                Bullying1  SexualAbuseByOlderPerson1  \n                  0.48405                    0.46540  \n   ParentalPhysicalAbuse1        ParentSubstanceUse1  \n                  0.71713                   -0.15917  \n     ParentIncarceration1       SchoolConnectedness1  \n                  0.07048                   -0.25542  \n      ParentalMonitoring1  UnfairDisciplineAtSchool1  \n                  0.59860                   -0.24268  \n            Homelessness1  \n                  1.18053  \n\nDegrees of Freedom: 14695 Total (i.e. Null);  14685 Residual\nNull Deviance:      5238 \nResidual Deviance: 4872     AIC: 4894\n\n\n\ntidy_model &lt;- \n  mod_1 |&gt;\n  tidy(exponentiate = TRUE,\n       conf.int = TRUE, \n       conf.level = .95) |&gt;\n  mutate(p.value = scales::pvalue(p.value))\n\ntidy_model\n\n# A tibble: 11 Ã— 7\n   term                  estimate std.error statistic p.value conf.low conf.high\n   &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)             0.0369    0.166    -19.9   &lt;0.001    0.0266    0.0508\n 2 AttackedInNeighborhoâ€¦   2.12      0.0954     7.85  &lt;0.001    1.75      2.55  \n 3 Bullying1               1.62      0.0919     5.27  &lt;0.001    1.35      1.94  \n 4 SexualAbuseByOlderPeâ€¦   1.59      0.133      3.51  &lt;0.001    1.22      2.06  \n 5 ParentalPhysicalAbusâ€¦   2.05      0.179      4.01  &lt;0.001    1.43      2.89  \n 6 ParentSubstanceUse1     0.853     0.111     -1.44  0.151     0.688     1.06  \n 7 ParentIncarceration1    1.07      0.126      0.560 0.575     0.841     1.38  \n 8 SchoolConnectedness1    0.775     0.0970    -2.63  0.008     0.639     0.935 \n 9 ParentalMonitoring1     1.82      0.114      5.26  &lt;0.001    1.45      2.27  \n10 UnfairDisciplineAtScâ€¦   0.785     0.114     -2.13  0.033     0.629     0.984 \n11 Homelessness1           3.26      0.155      7.61  &lt;0.001    2.39      4.39  \n\n\n\n\nModel Evaluation\n\nweapon_pred &lt;- \n  augment(mod_1, analysis_train) |&gt; \n  select(WeaponCarryingSchool, .pred_class, .pred_1, .pred_0)\n\nweapon_pred\n\n# A tibble: 14,696 Ã— 4\n   WeaponCarryingSchool .pred_class .pred_1 .pred_0\n   &lt;fct&gt;                &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;\n 1 0                    0            0.0360   0.964\n 2 0                    0            0.0412   0.959\n 3 0                    0            0.0241   0.976\n 4 0                    0            0.0317   0.968\n 5 0                    0            0.128    0.872\n 6 0                    0            0.0360   0.964\n 7 0                    0            0.0201   0.980\n 8 0                    0            0.0201   0.980\n 9 0                    0            0.0471   0.953\n10 0                    0            0.0531   0.947\n# â„¹ 14,686 more rows\n\n\n\nroc_plot_training &lt;- \n  weapon_pred |&gt; \n  roc_curve(truth = WeaponCarryingSchool, .pred_1, event_level = \"second\") |&gt; \n  autoplot()\n\nroc_plot_training \n\n\n\n\n\n\n\n\n\n\nVisualizations\n\ntidy_model |&gt; \n  filter(term != \"(Intercept)\") |&gt; \n  ggplot(aes(x = estimate, y = reorder(term, estimate))) +\n  geom_point(size = 3) +\n  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high), height = 0.2) +\n  geom_vline(xintercept = 1, linetype = \"dashed\", color = \"red\") +\n  scale_x_log10() +\n  labs(\n    x = \"Odds Ratio (log scale)\",\n    y = \"Predictors\",\n    title = \"Forest Plot of Logistic Regression Coefficients\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_text(size = 10),\n    plot.title = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\n\n\n\nResults and Interpretation\n\n\nKey Takeaways"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning Notebook ğŸ‘€",
    "section": "",
    "text": "This website will be our Machine Learning course, where we explore various statistical and machine learning models using the Youth Risk Behavior Survey (YRBS) 2023 dataset. Through this course, I learned to implement and understand different modeling techniques using the tidymodels framework in R.\n\nWhat Youâ€™ll Find Here\n\nAbout Me: A little bit about me and my research interests.\nThe Dataset: Information about my primary dataset and the research question I am trying to answer.\nModel Implementations: Hands-on examples of different models to answer the question:\n\nLogistic Regression\nLasso Regression\nDecision Trees\nRandom Forest\nK-Nearest Neighbors (KNN)"
  },
  {
    "objectID": "models/trees.html",
    "href": "models/trees.html",
    "title": "Classification Tree",
    "section": "",
    "text": "analysis_train &lt;- readRDS(here(\"models\",\"data\", \"analysis_train.rds\"))\nanalysis_folds &lt;- readRDS(here(\"models\",\"data\", \"analysis_folds.rds\"))\n\n\n\n\n\ncarry_weapon_recipe_tree &lt;- \n  recipe(formula = WeaponCarryingSchool ~ ., data = analysis_train) |&gt;\n  step_impute_mode(all_nominal_predictors()) |&gt;\n  step_impute_mean(all_numeric_predictors())\n\n\n\n\n\ncarry_weapon_spec_tree &lt;-\n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune(),\n    min_n = tune()\n  ) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"classification\")\n\n\n\n\n\ncarry_weapon_workflow_tree &lt;-\n  workflow() |&gt;\n  add_recipe(carry_weapon_recipe_tree) |&gt;\n  add_model(carry_weapon_spec_tree)\n\ncarry_weapon_workflow_tree\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: decision_tree()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n2 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n  min_n = tune()\n\nComputational engine: rpart \n\n\n\n\n\n\ntree_grid &lt;-\n  grid_regular(\n    cost_complexity(),\n    tree_depth(c(2,5)),\n    min_n(),\n    levels = 2)\ntree_grid\n\n# A tibble: 8 Ã— 3\n  cost_complexity tree_depth min_n\n            &lt;dbl&gt;      &lt;int&gt; &lt;int&gt;\n1    0.0000000001          2     2\n2    0.1                   2     2\n3    0.0000000001          5     2\n4    0.1                   5     2\n5    0.0000000001          2    40\n6    0.1                   2    40\n7    0.0000000001          5    40\n8    0.1                   5    40\n\n\n\n\n\n\ncart_tune &lt;- \n  carry_weapon_workflow_tree %&gt;% \n  tune_grid(resamples = analysis_folds,\n            grid = tree_grid, \n            metrics = metric_set(roc_auc),\n            control = control_grid(save_pred = TRUE)\n  )\n\nsaveRDS(cart_tune, here(\"model_outputs\", \"tree_tune.rds\"))\n\n\n\n\n\nshow_best(cart_tune, metric = \"roc_auc\")\n\n# A tibble: 5 Ã— 9\n  cost_complexity tree_depth min_n .metric .estimator  mean     n std_err\n            &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n1    0.0000000001          5     2 roc_auc binary     0.592     5 0.0226 \n2    0.0000000001          5    40 roc_auc binary     0.534     5 0.0167 \n3    0.0000000001          2     2 roc_auc binary     0.507     5 0.00740\n4    0.0000000001          2    40 roc_auc binary     0.507     5 0.00740\n5    0.1                   2     2 roc_auc binary     0.5       5 0      \n# â„¹ 1 more variable: .config &lt;chr&gt;\n\nautoplot(cart_tune)\n\n\n\n\n\n\n\n\n\n\n\n\nbest_weapon_carrying_tree &lt;- select_best(\n  cart_tune, \n  metric = \"roc_auc\")\nbest_weapon_carrying_tree\n\n# A tibble: 1 Ã— 4\n  cost_complexity tree_depth min_n .config             \n            &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;               \n1    0.0000000001          5     2 Preprocessor1_Model3\n\n# cost_complexity = 1e-10; This is extremely small, meaning almost no penalty is applied for having a more complex tree. OVERFITTING\n\n\n\n\n\ncarry_weapon_final_workflow_tree &lt;-\n  finalize_workflow(carry_weapon_workflow_tree, best_weapon_carrying_tree)\ncarry_weapon_final_workflow_tree\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: decision_tree()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n2 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 1e-10\n  tree_depth = 5\n  min_n = 2\n\nComputational engine: rpart \n\n\n\n\n\n\ncarry_weapon_fit_tree &lt;- fit(\n  carry_weapon_final_workflow_tree, \n  analysis_train)\ncarry_weapon_fit_tree\nsaveRDS(carry_weapon_fit_tree, here(\"model_outputs\", \"tree_fit.rds\"))\n\n\n\n\n\nweapon_pred_tree &lt;-\n  augment(carry_weapon_fit_tree, analysis_train) |&gt;\n  select(WeaponCarryingSchool, .pred_class, .pred_1, .pred_0)\n\n\n\n\n\nroc_plot_training_tree &lt;- \n  weapon_pred_tree |&gt; \n  roc_curve(truth = WeaponCarryingSchool, \n           .pred_0) |&gt; \n  autoplot()\nroc_plot_training_tree\n# very bad sensitivity vs specificity\n\nsaveRDS(roc_plot_training_tree, here(\"roc_graphs\", \"tree.rds\"))\n\n\n\n\n\nfit_resamples(carry_weapon_final_workflow_tree, \n              resamples = analysis_folds) |&gt; \n  collect_metrics()\n\n# A tibble: 3 Ã— 6\n  .metric     .estimator   mean     n std_err .config             \n  &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary     0.955      5 0.00141 Preprocessor1_Model1\n2 brier_class binary     0.0412     5 0.00135 Preprocessor1_Model1\n3 roc_auc     binary     0.592      5 0.0226  Preprocessor1_Model1\n\n# area under curve = 0.592; accuracy = 0.955\n\n\n\n\n\ncarry_weapon_fit_tree |&gt; \n  extract_fit_engine() |&gt; \n  rpart.plot::rpart.plot(roundint=FALSE)\n\n\n\n\n\n\n\nFigureÂ 1"
  },
  {
    "objectID": "models/trees.html#loading-the-data",
    "href": "models/trees.html#loading-the-data",
    "title": "Classification Tree",
    "section": "",
    "text": "analysis_train &lt;- readRDS(here(\"models\",\"data\", \"analysis_train.rds\"))\nanalysis_folds &lt;- readRDS(here(\"models\",\"data\", \"analysis_folds.rds\"))"
  },
  {
    "objectID": "models/trees.html#reciepe",
    "href": "models/trees.html#reciepe",
    "title": "Classification Tree",
    "section": "",
    "text": "carry_weapon_recipe_tree &lt;- \n  recipe(formula = WeaponCarryingSchool ~ ., data = analysis_train) |&gt;\n  step_impute_mode(all_nominal_predictors()) |&gt;\n  step_impute_mean(all_numeric_predictors())"
  },
  {
    "objectID": "models/trees.html#model-specification",
    "href": "models/trees.html#model-specification",
    "title": "Classification Tree",
    "section": "",
    "text": "carry_weapon_spec_tree &lt;-\n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune(),\n    min_n = tune()\n  ) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"classification\")"
  },
  {
    "objectID": "models/trees.html#creating-the-workflow",
    "href": "models/trees.html#creating-the-workflow",
    "title": "Classification Tree",
    "section": "",
    "text": "carry_weapon_workflow_tree &lt;-\n  workflow() |&gt;\n  add_recipe(carry_weapon_recipe_tree) |&gt;\n  add_model(carry_weapon_spec_tree)\n\ncarry_weapon_workflow_tree\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: decision_tree()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n2 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n  min_n = tune()\n\nComputational engine: rpart"
  },
  {
    "objectID": "models/trees.html#model-tuning---tuning-for-the-tree---the-grid",
    "href": "models/trees.html#model-tuning---tuning-for-the-tree---the-grid",
    "title": "Classification Tree",
    "section": "",
    "text": "tree_grid &lt;-\n  grid_regular(\n    cost_complexity(),\n    tree_depth(c(2,5)),\n    min_n(),\n    levels = 2)\ntree_grid\n\n# A tibble: 8 Ã— 3\n  cost_complexity tree_depth min_n\n            &lt;dbl&gt;      &lt;int&gt; &lt;int&gt;\n1    0.0000000001          2     2\n2    0.1                   2     2\n3    0.0000000001          5     2\n4    0.1                   5     2\n5    0.0000000001          2    40\n6    0.1                   2    40\n7    0.0000000001          5    40\n8    0.1                   5    40"
  },
  {
    "objectID": "models/trees.html#tuning-for-the-tree",
    "href": "models/trees.html#tuning-for-the-tree",
    "title": "Classification Tree",
    "section": "",
    "text": "cart_tune &lt;- \n  carry_weapon_workflow_tree %&gt;% \n  tune_grid(resamples = analysis_folds,\n            grid = tree_grid, \n            metrics = metric_set(roc_auc),\n            control = control_grid(save_pred = TRUE)\n  )\n\nsaveRDS(cart_tune, here(\"model_outputs\", \"tree_tune.rds\"))"
  },
  {
    "objectID": "models/trees.html#choosing-the-best-cp",
    "href": "models/trees.html#choosing-the-best-cp",
    "title": "Classification Tree",
    "section": "",
    "text": "show_best(cart_tune, metric = \"roc_auc\")\n\n# A tibble: 5 Ã— 9\n  cost_complexity tree_depth min_n .metric .estimator  mean     n std_err\n            &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n1    0.0000000001          5     2 roc_auc binary     0.592     5 0.0226 \n2    0.0000000001          5    40 roc_auc binary     0.534     5 0.0167 \n3    0.0000000001          2     2 roc_auc binary     0.507     5 0.00740\n4    0.0000000001          2    40 roc_auc binary     0.507     5 0.00740\n5    0.1                   2     2 roc_auc binary     0.5       5 0      \n# â„¹ 1 more variable: .config &lt;chr&gt;\n\nautoplot(cart_tune)"
  },
  {
    "objectID": "models/trees.html#choosing-the-best-hyperparameters",
    "href": "models/trees.html#choosing-the-best-hyperparameters",
    "title": "Classification Tree",
    "section": "",
    "text": "best_weapon_carrying_tree &lt;- select_best(\n  cart_tune, \n  metric = \"roc_auc\")\nbest_weapon_carrying_tree\n\n# A tibble: 1 Ã— 4\n  cost_complexity tree_depth min_n .config             \n            &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;               \n1    0.0000000001          5     2 Preprocessor1_Model3\n\n# cost_complexity = 1e-10; This is extremely small, meaning almost no penalty is applied for having a more complex tree. OVERFITTING"
  },
  {
    "objectID": "models/trees.html#finalize-the-workflow",
    "href": "models/trees.html#finalize-the-workflow",
    "title": "Classification Tree",
    "section": "",
    "text": "carry_weapon_final_workflow_tree &lt;-\n  finalize_workflow(carry_weapon_workflow_tree, best_weapon_carrying_tree)\ncarry_weapon_final_workflow_tree\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: decision_tree()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n2 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 1e-10\n  tree_depth = 5\n  min_n = 2\n\nComputational engine: rpart"
  },
  {
    "objectID": "models/trees.html#fit-the-tree",
    "href": "models/trees.html#fit-the-tree",
    "title": "Classification Tree",
    "section": "",
    "text": "carry_weapon_fit_tree &lt;- fit(\n  carry_weapon_final_workflow_tree, \n  analysis_train)\ncarry_weapon_fit_tree\nsaveRDS(carry_weapon_fit_tree, here(\"model_outputs\", \"tree_fit.rds\"))"
  },
  {
    "objectID": "models/trees.html#predictions-review-fit-on-the-training-data",
    "href": "models/trees.html#predictions-review-fit-on-the-training-data",
    "title": "Classification Tree",
    "section": "",
    "text": "weapon_pred_tree &lt;-\n  augment(carry_weapon_fit_tree, analysis_train) |&gt;\n  select(WeaponCarryingSchool, .pred_class, .pred_1, .pred_0)"
  },
  {
    "objectID": "models/trees.html#roc-graph",
    "href": "models/trees.html#roc-graph",
    "title": "Classification Tree",
    "section": "",
    "text": "roc_plot_training_tree &lt;- \n  weapon_pred_tree |&gt; \n  roc_curve(truth = WeaponCarryingSchool, \n           .pred_0) |&gt; \n  autoplot()\nroc_plot_training_tree\n# very bad sensitivity vs specificity\n\nsaveRDS(roc_plot_training_tree, here(\"roc_graphs\", \"tree.rds\"))"
  },
  {
    "objectID": "models/trees.html#review-on-resamples",
    "href": "models/trees.html#review-on-resamples",
    "title": "Classification Tree",
    "section": "",
    "text": "fit_resamples(carry_weapon_final_workflow_tree, \n              resamples = analysis_folds) |&gt; \n  collect_metrics()\n\n# A tibble: 3 Ã— 6\n  .metric     .estimator   mean     n std_err .config             \n  &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary     0.955      5 0.00141 Preprocessor1_Model1\n2 brier_class binary     0.0412     5 0.00135 Preprocessor1_Model1\n3 roc_auc     binary     0.592      5 0.0226  Preprocessor1_Model1\n\n# area under curve = 0.592; accuracy = 0.955"
  },
  {
    "objectID": "models/trees.html#plot-the-tree",
    "href": "models/trees.html#plot-the-tree",
    "title": "Classification Tree",
    "section": "",
    "text": "carry_weapon_fit_tree |&gt; \n  extract_fit_engine() |&gt; \n  rpart.plot::rpart.plot(roundint=FALSE)\n\n\n\n\n\n\n\nFigureÂ 1"
  },
  {
    "objectID": "models/forest.html",
    "href": "models/forest.html",
    "title": "Random Forest",
    "section": "",
    "text": "analysis_train &lt;- readRDS(here(\"models\",\"data\", \"analysis_train.rds\"))\nanalysis_folds &lt;- readRDS(here(\"models\",\"data\", \"analysis_folds.rds\"))\n\n\n\n\n\nset.seed(2023)\nWeaponCarry_split &lt;- initial_split(analysis_train, \n                               strata = WeaponCarryingSchool)\nweapon_train &lt;- training(WeaponCarry_split)\nweapon_test &lt;- testing(WeaponCarry_split)\n\nWeaponCarry_split\n\n&lt;Training/Testing/Total&gt;\n&lt;11022/3674/14696&gt;\n\n\n\n\n\n\nweapon_train |&gt;\n  tabyl(WeaponCarryingSchool)  |&gt;\n  adorn_pct_formatting(0) |&gt;\n  adorn_totals()\n\n WeaponCarryingSchool     n percent\n                    0 10528     96%\n                    1   494      4%\n                Total 11022       -\n\nweapon_test |&gt;\n  tabyl(WeaponCarryingSchool)  |&gt;\n  adorn_pct_formatting(0) |&gt;\n  adorn_totals()\n\n WeaponCarryingSchool    n percent\n                    0 3532     96%\n                    1  142      4%\n                Total 3674       -\n\n\n\n\n\n\nset.seed(2023)\n\ncv_weapon &lt;- rsample::vfold_cv(weapon_train, \n                                v= 5,\n                                strata = WeaponCarryingSchool)\ncv_weapon\n\n#  5-fold cross-validation using stratification \n# A tibble: 5 Ã— 2\n  splits              id   \n  &lt;list&gt;              &lt;chr&gt;\n1 &lt;split [8817/2205]&gt; Fold1\n2 &lt;split [8817/2205]&gt; Fold2\n3 &lt;split [8818/2204]&gt; Fold3\n4 &lt;split [8818/2204]&gt; Fold4\n5 &lt;split [8818/2204]&gt; Fold5\n\n\n\n\n\n\ncarry_weapon_recipe_forest &lt;- \n  recipe(formula = WeaponCarryingSchool ~ ., data = weapon_train) |&gt;\n  step_impute_mode(all_nominal_predictors()) |&gt;\n  step_impute_mean(all_numeric_predictors()) |&gt;\n  step_dummy(all_nominal_predictors())\n\n\n\n\n\nranger_spec &lt;- \n  rand_forest(\n    # the number of predictors to sample at each split\n    mtry = tune(), \n    # the number of observations needed to keep splitting nodes\n    min_n = tune(),\n    trees = 100) |&gt;  \n  set_mode(\"classification\") |&gt;  \n  set_engine(\"ranger\", \n             # This is essential for vip()\n             importance = \"permutation\") \n\nranger_spec\n\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 100\n  min_n = tune()\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n\n\n\n\n\n\nranger_workflow &lt;- \n  workflow() |&gt; \n  add_recipe(carry_weapon_recipe_forest) |&gt;  \n  add_model(ranger_spec) \n\nranger_workflow\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: rand_forest()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n3 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_dummy()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 100\n  min_n = tune()\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n\n\n\n\n\n\n#doParallel::registerDoParallel()\n  \nset.seed(46257)\n  \nranger_tune &lt;-\n  tune_grid(\n    ranger_workflow,\n    resamples = cv_weapon,\n# grid = 11 says to choose 11 parameter sets automatically \n    grid = 11)\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n#doParallel::stopImplicitCluster()\n\nsaveRDS(ranger_tune, here(\"models\", \"model_outputs\", \"forest_tune.rds\"))\n\n\n\n\n\ncollect_metrics(ranger_tune)\n\n# A tibble: 33 Ã— 8\n    mtry min_n .metric     .estimator   mean     n std_err .config              \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1     1    17 accuracy    binary     0.955      5 0.00162 Preprocessor1_Model01\n 2     1    17 brier_class binary     0.0416     5 0.00140 Preprocessor1_Model01\n 3     1    17 roc_auc     binary     0.689      5 0.00889 Preprocessor1_Model01\n 4     1    32 accuracy    binary     0.955      5 0.00162 Preprocessor1_Model02\n 5     1    32 brier_class binary     0.0416     5 0.00139 Preprocessor1_Model02\n 6     1    32 roc_auc     binary     0.688      5 0.00810 Preprocessor1_Model02\n 7     2     5 accuracy    binary     0.955      5 0.00157 Preprocessor1_Model03\n 8     2     5 brier_class binary     0.0415     5 0.00132 Preprocessor1_Model03\n 9     2     5 roc_auc     binary     0.688      5 0.0113  Preprocessor1_Model03\n10     3    21 accuracy    binary     0.955      5 0.00162 Preprocessor1_Model04\n# â„¹ 23 more rows\n\n\n\n\n\n\nautoplot(ranger_tune)\n\n\n\n\n\n\n\n\n\n\n\n\nbest_weapon_carrying_forest &lt;- select_best(ranger_tune, metric = \"roc_auc\")\nbest_weapon_carrying_forest\n\n# A tibble: 1 Ã— 3\n   mtry min_n .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;                \n1     1    17 Preprocessor1_Model01\n\n# cost_complexity = 1e-10; This is extremely small, meaning almost no penalty is applied for having a more complex tree. OVERFITTING\n\n\n\n\n\ncarry_weapon_final_workflow_forest &lt;-\n  finalize_workflow(ranger_workflow, best_weapon_carrying_forest)\ncarry_weapon_final_workflow_forest\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: rand_forest()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n3 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_dummy()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = 1\n  trees = 100\n  min_n = 17\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n\n\n\n\n\n\ncarry_weapon_fit_forest &lt;- fit(carry_weapon_final_workflow_forest, \n                               weapon_train)\ncarry_weapon_fit_forest\n\nsaveRDS(carry_weapon_fit_forest, here(\"models\",\"model_outputs\", \"forest_fit.rds\"))\n\n\n\n\n\nweapon_pred_forest &lt;-\n  augment(carry_weapon_fit_forest, weapon_train) |&gt;\n  select(WeaponCarryingSchool, .pred_class, .pred_1, .pred_0)\nweapon_pred_forest\n\n# A tibble: 11,022 Ã— 4\n   WeaponCarryingSchool .pred_class .pred_1 .pred_0\n   &lt;fct&gt;                &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;\n 1 0                    0            0.0470   0.953\n 2 0                    0            0.0328   0.967\n 3 0                    0            0.105    0.895\n 4 0                    0            0.0470   0.953\n 5 0                    0            0.0321   0.968\n 6 0                    0            0.0321   0.968\n 7 0                    0            0.0466   0.953\n 8 0                    0            0.0470   0.953\n 9 0                    0            0.0321   0.968\n10 0                    0            0.0669   0.933\n# â„¹ 11,012 more rows\n\n\n\n\n\n\nroc_plot_training_forest &lt;- \n  weapon_pred_forest |&gt; \n  roc_curve(truth = WeaponCarryingSchool, \n           .pred_0) |&gt; \n  autoplot()\nroc_plot_training_forest\n\nsaveRDS(roc_plot_training_forest, here(\"models\",\"roc_graphs\", \"forest.rds\"))"
  },
  {
    "objectID": "models/forest.html#loading-the-data",
    "href": "models/forest.html#loading-the-data",
    "title": "Random Forest",
    "section": "",
    "text": "analysis_train &lt;- readRDS(here(\"models\",\"data\", \"analysis_train.rds\"))\nanalysis_folds &lt;- readRDS(here(\"models\",\"data\", \"analysis_folds.rds\"))"
  },
  {
    "objectID": "models/forest.html#splitting-the-data",
    "href": "models/forest.html#splitting-the-data",
    "title": "Random Forest",
    "section": "",
    "text": "set.seed(2023)\nWeaponCarry_split &lt;- initial_split(analysis_train, \n                               strata = WeaponCarryingSchool)\nweapon_train &lt;- training(WeaponCarry_split)\nweapon_test &lt;- testing(WeaponCarry_split)\n\nWeaponCarry_split\n\n&lt;Training/Testing/Total&gt;\n&lt;11022/3674/14696&gt;"
  },
  {
    "objectID": "models/forest.html#check-our-work",
    "href": "models/forest.html#check-our-work",
    "title": "Random Forest",
    "section": "",
    "text": "weapon_train |&gt;\n  tabyl(WeaponCarryingSchool)  |&gt;\n  adorn_pct_formatting(0) |&gt;\n  adorn_totals()\n\n WeaponCarryingSchool     n percent\n                    0 10528     96%\n                    1   494      4%\n                Total 11022       -\n\nweapon_test |&gt;\n  tabyl(WeaponCarryingSchool)  |&gt;\n  adorn_pct_formatting(0) |&gt;\n  adorn_totals()\n\n WeaponCarryingSchool    n percent\n                    0 3532     96%\n                    1  142      4%\n                Total 3674       -"
  },
  {
    "objectID": "models/forest.html#creating-the-resampling-object",
    "href": "models/forest.html#creating-the-resampling-object",
    "title": "Random Forest",
    "section": "",
    "text": "set.seed(2023)\n\ncv_weapon &lt;- rsample::vfold_cv(weapon_train, \n                                v= 5,\n                                strata = WeaponCarryingSchool)\ncv_weapon\n\n#  5-fold cross-validation using stratification \n# A tibble: 5 Ã— 2\n  splits              id   \n  &lt;list&gt;              &lt;chr&gt;\n1 &lt;split [8817/2205]&gt; Fold1\n2 &lt;split [8817/2205]&gt; Fold2\n3 &lt;split [8818/2204]&gt; Fold3\n4 &lt;split [8818/2204]&gt; Fold4\n5 &lt;split [8818/2204]&gt; Fold5"
  },
  {
    "objectID": "models/forest.html#reciepe",
    "href": "models/forest.html#reciepe",
    "title": "Random Forest",
    "section": "",
    "text": "carry_weapon_recipe_forest &lt;- \n  recipe(formula = WeaponCarryingSchool ~ ., data = weapon_train) |&gt;\n  step_impute_mode(all_nominal_predictors()) |&gt;\n  step_impute_mean(all_numeric_predictors()) |&gt;\n  step_dummy(all_nominal_predictors())"
  },
  {
    "objectID": "models/forest.html#model-specification",
    "href": "models/forest.html#model-specification",
    "title": "Random Forest",
    "section": "",
    "text": "ranger_spec &lt;- \n  rand_forest(\n    # the number of predictors to sample at each split\n    mtry = tune(), \n    # the number of observations needed to keep splitting nodes\n    min_n = tune(),\n    trees = 100) |&gt;  \n  set_mode(\"classification\") |&gt;  \n  set_engine(\"ranger\", \n             # This is essential for vip()\n             importance = \"permutation\") \n\nranger_spec\n\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 100\n  min_n = tune()\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger"
  },
  {
    "objectID": "models/forest.html#creating-the-workflow",
    "href": "models/forest.html#creating-the-workflow",
    "title": "Random Forest",
    "section": "",
    "text": "ranger_workflow &lt;- \n  workflow() |&gt; \n  add_recipe(carry_weapon_recipe_forest) |&gt;  \n  add_model(ranger_spec) \n\nranger_workflow\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: rand_forest()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n3 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_dummy()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 100\n  min_n = tune()\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger"
  },
  {
    "objectID": "models/forest.html#model-tuning",
    "href": "models/forest.html#model-tuning",
    "title": "Random Forest",
    "section": "",
    "text": "#doParallel::registerDoParallel()\n  \nset.seed(46257)\n  \nranger_tune &lt;-\n  tune_grid(\n    ranger_workflow,\n    resamples = cv_weapon,\n# grid = 11 says to choose 11 parameter sets automatically \n    grid = 11)\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n#doParallel::stopImplicitCluster()\n\nsaveRDS(ranger_tune, here(\"models\", \"model_outputs\", \"forest_tune.rds\"))"
  },
  {
    "objectID": "models/forest.html#collect-the-tunning-metrics",
    "href": "models/forest.html#collect-the-tunning-metrics",
    "title": "Random Forest",
    "section": "",
    "text": "collect_metrics(ranger_tune)\n\n# A tibble: 33 Ã— 8\n    mtry min_n .metric     .estimator   mean     n std_err .config              \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1     1    17 accuracy    binary     0.955      5 0.00162 Preprocessor1_Model01\n 2     1    17 brier_class binary     0.0416     5 0.00140 Preprocessor1_Model01\n 3     1    17 roc_auc     binary     0.689      5 0.00889 Preprocessor1_Model01\n 4     1    32 accuracy    binary     0.955      5 0.00162 Preprocessor1_Model02\n 5     1    32 brier_class binary     0.0416     5 0.00139 Preprocessor1_Model02\n 6     1    32 roc_auc     binary     0.688      5 0.00810 Preprocessor1_Model02\n 7     2     5 accuracy    binary     0.955      5 0.00157 Preprocessor1_Model03\n 8     2     5 brier_class binary     0.0415     5 0.00132 Preprocessor1_Model03\n 9     2     5 roc_auc     binary     0.688      5 0.0113  Preprocessor1_Model03\n10     3    21 accuracy    binary     0.955      5 0.00162 Preprocessor1_Model04\n# â„¹ 23 more rows"
  },
  {
    "objectID": "models/forest.html#visualize-the-metrics",
    "href": "models/forest.html#visualize-the-metrics",
    "title": "Random Forest",
    "section": "",
    "text": "autoplot(ranger_tune)"
  },
  {
    "objectID": "models/forest.html#choosing-the-best-hyperparameters",
    "href": "models/forest.html#choosing-the-best-hyperparameters",
    "title": "Random Forest",
    "section": "",
    "text": "best_weapon_carrying_forest &lt;- select_best(ranger_tune, metric = \"roc_auc\")\nbest_weapon_carrying_forest\n\n# A tibble: 1 Ã— 3\n   mtry min_n .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;                \n1     1    17 Preprocessor1_Model01\n\n# cost_complexity = 1e-10; This is extremely small, meaning almost no penalty is applied for having a more complex tree. OVERFITTING"
  },
  {
    "objectID": "models/forest.html#finalize-the-workflow",
    "href": "models/forest.html#finalize-the-workflow",
    "title": "Random Forest",
    "section": "",
    "text": "carry_weapon_final_workflow_forest &lt;-\n  finalize_workflow(ranger_workflow, best_weapon_carrying_forest)\ncarry_weapon_final_workflow_forest\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: rand_forest()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n3 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_dummy()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = 1\n  trees = 100\n  min_n = 17\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger"
  },
  {
    "objectID": "models/forest.html#fit-the-forest",
    "href": "models/forest.html#fit-the-forest",
    "title": "Random Forest",
    "section": "",
    "text": "carry_weapon_fit_forest &lt;- fit(carry_weapon_final_workflow_forest, \n                               weapon_train)\ncarry_weapon_fit_forest\n\nsaveRDS(carry_weapon_fit_forest, here(\"models\",\"model_outputs\", \"forest_fit.rds\"))"
  },
  {
    "objectID": "models/forest.html#predictions-review-fit-on-the-training-data",
    "href": "models/forest.html#predictions-review-fit-on-the-training-data",
    "title": "Random Forest",
    "section": "",
    "text": "weapon_pred_forest &lt;-\n  augment(carry_weapon_fit_forest, weapon_train) |&gt;\n  select(WeaponCarryingSchool, .pred_class, .pred_1, .pred_0)\nweapon_pred_forest\n\n# A tibble: 11,022 Ã— 4\n   WeaponCarryingSchool .pred_class .pred_1 .pred_0\n   &lt;fct&gt;                &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;\n 1 0                    0            0.0470   0.953\n 2 0                    0            0.0328   0.967\n 3 0                    0            0.105    0.895\n 4 0                    0            0.0470   0.953\n 5 0                    0            0.0321   0.968\n 6 0                    0            0.0321   0.968\n 7 0                    0            0.0466   0.953\n 8 0                    0            0.0470   0.953\n 9 0                    0            0.0321   0.968\n10 0                    0            0.0669   0.933\n# â„¹ 11,012 more rows"
  },
  {
    "objectID": "models/forest.html#roc-graph",
    "href": "models/forest.html#roc-graph",
    "title": "Random Forest",
    "section": "",
    "text": "roc_plot_training_forest &lt;- \n  weapon_pred_forest |&gt; \n  roc_curve(truth = WeaponCarryingSchool, \n           .pred_0) |&gt; \n  autoplot()\nroc_plot_training_forest\n\nsaveRDS(roc_plot_training_forest, here(\"models\",\"roc_graphs\", \"forest.rds\"))"
  },
  {
    "objectID": "models/ROC_Graph.html",
    "href": "models/ROC_Graph.html",
    "title": "ROC_Graph",
    "section": "",
    "text": "roc_logistic &lt;- readRDS(\"roc_graphs/logistic.rds\")\nroc_lasso &lt;- readRDS(\"roc_graphs/lasso.rds\")\nroc_random &lt;- readRDS(\"roc_graphs/forest.rds\")\n\nlogistic &lt;- roc_logistic$data |&gt;\n  mutate(model = \"logistic\")\n\nlasso &lt;- roc_lasso$data |&gt;\n  mutate(model = \"lasso\")\n\nrandom &lt;- roc_random$data |&gt;\n  mutate(model = \"random\")\n\ncompare_roc &lt;- \n  bind_rows(\n    logistic,lasso,random\n  ) |&gt;\n  ggplot(\n    aes(x = 1 - specificity, y = sensitivity, col = model) \n  ) + \n  geom_path(lwd = 0.5, alpha = 1) + \n  geom_abline(lty = 2) + \n  coord_equal()\n\ncompare_roc"
  },
  {
    "objectID": "models/random-forest.html",
    "href": "models/random-forest.html",
    "title": "Random Forest",
    "section": "",
    "text": "analysis_train &lt;- readRDS(here(\"models\",\"data\", \"analysis_train.rds\"))\nanalysis_folds &lt;- readRDS(here(\"models\",\"data\", \"analysis_folds.rds\"))\n\n\n\n\n\nset.seed(2023)\nWeaponCarry_split &lt;- initial_split(analysis_train, \n                               strata = WeaponCarryingSchool)\nweapon_train &lt;- training(WeaponCarry_split)\nweapon_test &lt;- testing(WeaponCarry_split)\n\nWeaponCarry_split\n\n&lt;Training/Testing/Total&gt;\n&lt;11022/3674/14696&gt;\n\n\n\n\n\n\nweapon_train |&gt;\n  tabyl(WeaponCarryingSchool)  |&gt;\n  adorn_pct_formatting(0) |&gt;\n  adorn_totals()\n\n WeaponCarryingSchool     n percent\n                    0 10528     96%\n                    1   494      4%\n                Total 11022       -\n\nweapon_test |&gt;\n  tabyl(WeaponCarryingSchool)  |&gt;\n  adorn_pct_formatting(0) |&gt;\n  adorn_totals()\n\n WeaponCarryingSchool    n percent\n                    0 3532     96%\n                    1  142      4%\n                Total 3674       -\n\n\n\n\n\n\nset.seed(2023)\n\ncv_weapon &lt;- rsample::vfold_cv(weapon_train, \n                                v= 5,\n                                strata = WeaponCarryingSchool)\ncv_weapon\n\n#  5-fold cross-validation using stratification \n# A tibble: 5 Ã— 2\n  splits              id   \n  &lt;list&gt;              &lt;chr&gt;\n1 &lt;split [8817/2205]&gt; Fold1\n2 &lt;split [8817/2205]&gt; Fold2\n3 &lt;split [8818/2204]&gt; Fold3\n4 &lt;split [8818/2204]&gt; Fold4\n5 &lt;split [8818/2204]&gt; Fold5\n\n\n\n\n\n\ncarry_weapon_recipe_forest &lt;- \n  recipe(formula = WeaponCarryingSchool ~ ., data = weapon_train) |&gt;\n  step_impute_mode(all_nominal_predictors()) |&gt;\n  step_impute_mean(all_numeric_predictors()) |&gt;\n  step_dummy(all_nominal_predictors())\n\n\n\n\n\nranger_spec &lt;- \n  rand_forest(\n    # the number of predictors to sample at each split\n    mtry = tune(), \n    # the number of observations needed to keep splitting nodes\n    min_n = tune(),\n    trees = 100) |&gt;  \n  set_mode(\"classification\") |&gt;  \n  set_engine(\"ranger\", \n             # This is essential for vip()\n             importance = \"permutation\") \n\nranger_spec\n\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 100\n  min_n = tune()\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n\n\n\n\n\n\nranger_workflow &lt;- \n  workflow() |&gt; \n  add_recipe(carry_weapon_recipe_forest) |&gt;  \n  add_model(ranger_spec) \n\nranger_workflow\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: rand_forest()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n3 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_dummy()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 100\n  min_n = tune()\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n\n\n\n\n\n\n#doParallel::registerDoParallel()\n  \nset.seed(46257)\n  \nranger_tune &lt;-\n  tune_grid(\n    ranger_workflow,\n    resamples = cv_weapon,\n# grid = 11 says to choose 11 parameter sets automatically \n    grid = 11)\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n#doParallel::stopImplicitCluster()\n\nsaveRDS(ranger_tune, here(\"models\", \"model_outputs\", \"forest_tune.rds\"))\n\n\n\n\n\ncollect_metrics(ranger_tune)\n\n# A tibble: 33 Ã— 8\n    mtry min_n .metric     .estimator   mean     n std_err .config              \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1     1    17 accuracy    binary     0.955      5 0.00162 Preprocessor1_Model01\n 2     1    17 brier_class binary     0.0416     5 0.00140 Preprocessor1_Model01\n 3     1    17 roc_auc     binary     0.689      5 0.00889 Preprocessor1_Model01\n 4     1    32 accuracy    binary     0.955      5 0.00162 Preprocessor1_Model02\n 5     1    32 brier_class binary     0.0416     5 0.00139 Preprocessor1_Model02\n 6     1    32 roc_auc     binary     0.688      5 0.00810 Preprocessor1_Model02\n 7     2     5 accuracy    binary     0.955      5 0.00157 Preprocessor1_Model03\n 8     2     5 brier_class binary     0.0415     5 0.00132 Preprocessor1_Model03\n 9     2     5 roc_auc     binary     0.688      5 0.0113  Preprocessor1_Model03\n10     3    21 accuracy    binary     0.955      5 0.00162 Preprocessor1_Model04\n# â„¹ 23 more rows\n\n\n\n\n\n\nautoplot(ranger_tune)\n\n\n\n\n\n\n\n\n\n\n\n\nbest_weapon_carrying_forest &lt;- select_best(ranger_tune, metric = \"roc_auc\")\nbest_weapon_carrying_forest\n\n# A tibble: 1 Ã— 3\n   mtry min_n .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;                \n1     1    17 Preprocessor1_Model01\n\n# cost_complexity = 1e-10; This is extremely small, meaning almost no penalty is applied for having a more complex tree. OVERFITTING\n\n\n\n\n\ncarry_weapon_final_workflow_forest &lt;-\n  finalize_workflow(ranger_workflow, best_weapon_carrying_forest)\ncarry_weapon_final_workflow_forest\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: rand_forest()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n3 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_dummy()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = 1\n  trees = 100\n  min_n = 17\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger \n\n\n\n\n\n\ncarry_weapon_fit_forest &lt;- fit(carry_weapon_final_workflow_forest, \n                               weapon_train)\ncarry_weapon_fit_forest\n\nsaveRDS(carry_weapon_fit_forest, here(\"models\",\"model_outputs\", \"forest_fit.rds\"))\n\n\n\n\n\nweapon_pred_forest &lt;-\n  augment(carry_weapon_fit_forest, weapon_train) |&gt;\n  select(WeaponCarryingSchool, .pred_class, .pred_1, .pred_0)\nweapon_pred_forest\n\n# A tibble: 11,022 Ã— 4\n   WeaponCarryingSchool .pred_class .pred_1 .pred_0\n   &lt;fct&gt;                &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;\n 1 0                    0            0.0470   0.953\n 2 0                    0            0.0328   0.967\n 3 0                    0            0.105    0.895\n 4 0                    0            0.0470   0.953\n 5 0                    0            0.0321   0.968\n 6 0                    0            0.0321   0.968\n 7 0                    0            0.0466   0.953\n 8 0                    0            0.0470   0.953\n 9 0                    0            0.0321   0.968\n10 0                    0            0.0669   0.933\n# â„¹ 11,012 more rows\n\n\n\n\n\n\nroc_plot_training_forest &lt;- \n  weapon_pred_forest |&gt; \n  roc_curve(truth = WeaponCarryingSchool, \n           .pred_0) |&gt; \n  autoplot()\nroc_plot_training_forest\n\nsaveRDS(roc_plot_training_forest, here(\"models\",\"roc_graphs\", \"forest.rds\"))"
  },
  {
    "objectID": "models/random-forest.html#loading-the-data",
    "href": "models/random-forest.html#loading-the-data",
    "title": "Random Forest",
    "section": "",
    "text": "analysis_train &lt;- readRDS(here(\"models\",\"data\", \"analysis_train.rds\"))\nanalysis_folds &lt;- readRDS(here(\"models\",\"data\", \"analysis_folds.rds\"))"
  },
  {
    "objectID": "models/random-forest.html#splitting-the-data",
    "href": "models/random-forest.html#splitting-the-data",
    "title": "Random Forest",
    "section": "",
    "text": "set.seed(2023)\nWeaponCarry_split &lt;- initial_split(analysis_train, \n                               strata = WeaponCarryingSchool)\nweapon_train &lt;- training(WeaponCarry_split)\nweapon_test &lt;- testing(WeaponCarry_split)\n\nWeaponCarry_split\n\n&lt;Training/Testing/Total&gt;\n&lt;11022/3674/14696&gt;"
  },
  {
    "objectID": "models/random-forest.html#check-our-work",
    "href": "models/random-forest.html#check-our-work",
    "title": "Random Forest",
    "section": "",
    "text": "weapon_train |&gt;\n  tabyl(WeaponCarryingSchool)  |&gt;\n  adorn_pct_formatting(0) |&gt;\n  adorn_totals()\n\n WeaponCarryingSchool     n percent\n                    0 10528     96%\n                    1   494      4%\n                Total 11022       -\n\nweapon_test |&gt;\n  tabyl(WeaponCarryingSchool)  |&gt;\n  adorn_pct_formatting(0) |&gt;\n  adorn_totals()\n\n WeaponCarryingSchool    n percent\n                    0 3532     96%\n                    1  142      4%\n                Total 3674       -"
  },
  {
    "objectID": "models/random-forest.html#creating-the-resampling-object",
    "href": "models/random-forest.html#creating-the-resampling-object",
    "title": "Random Forest",
    "section": "",
    "text": "set.seed(2023)\n\ncv_weapon &lt;- rsample::vfold_cv(weapon_train, \n                                v= 5,\n                                strata = WeaponCarryingSchool)\ncv_weapon\n\n#  5-fold cross-validation using stratification \n# A tibble: 5 Ã— 2\n  splits              id   \n  &lt;list&gt;              &lt;chr&gt;\n1 &lt;split [8817/2205]&gt; Fold1\n2 &lt;split [8817/2205]&gt; Fold2\n3 &lt;split [8818/2204]&gt; Fold3\n4 &lt;split [8818/2204]&gt; Fold4\n5 &lt;split [8818/2204]&gt; Fold5"
  },
  {
    "objectID": "models/random-forest.html#reciepe",
    "href": "models/random-forest.html#reciepe",
    "title": "Random Forest",
    "section": "",
    "text": "carry_weapon_recipe_forest &lt;- \n  recipe(formula = WeaponCarryingSchool ~ ., data = weapon_train) |&gt;\n  step_impute_mode(all_nominal_predictors()) |&gt;\n  step_impute_mean(all_numeric_predictors()) |&gt;\n  step_dummy(all_nominal_predictors())"
  },
  {
    "objectID": "models/random-forest.html#model-specification",
    "href": "models/random-forest.html#model-specification",
    "title": "Random Forest",
    "section": "",
    "text": "ranger_spec &lt;- \n  rand_forest(\n    # the number of predictors to sample at each split\n    mtry = tune(), \n    # the number of observations needed to keep splitting nodes\n    min_n = tune(),\n    trees = 100) |&gt;  \n  set_mode(\"classification\") |&gt;  \n  set_engine(\"ranger\", \n             # This is essential for vip()\n             importance = \"permutation\") \n\nranger_spec\n\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 100\n  min_n = tune()\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger"
  },
  {
    "objectID": "models/random-forest.html#creating-the-workflow",
    "href": "models/random-forest.html#creating-the-workflow",
    "title": "Random Forest",
    "section": "",
    "text": "ranger_workflow &lt;- \n  workflow() |&gt; \n  add_recipe(carry_weapon_recipe_forest) |&gt;  \n  add_model(ranger_spec) \n\nranger_workflow\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: rand_forest()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n3 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_dummy()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = tune()\n  trees = 100\n  min_n = tune()\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger"
  },
  {
    "objectID": "models/random-forest.html#model-tuning",
    "href": "models/random-forest.html#model-tuning",
    "title": "Random Forest",
    "section": "",
    "text": "#doParallel::registerDoParallel()\n  \nset.seed(46257)\n  \nranger_tune &lt;-\n  tune_grid(\n    ranger_workflow,\n    resamples = cv_weapon,\n# grid = 11 says to choose 11 parameter sets automatically \n    grid = 11)\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n#doParallel::stopImplicitCluster()\n\nsaveRDS(ranger_tune, here(\"models\", \"model_outputs\", \"forest_tune.rds\"))"
  },
  {
    "objectID": "models/random-forest.html#collect-the-tunning-metrics",
    "href": "models/random-forest.html#collect-the-tunning-metrics",
    "title": "Random Forest",
    "section": "",
    "text": "collect_metrics(ranger_tune)\n\n# A tibble: 33 Ã— 8\n    mtry min_n .metric     .estimator   mean     n std_err .config              \n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1     1    17 accuracy    binary     0.955      5 0.00162 Preprocessor1_Model01\n 2     1    17 brier_class binary     0.0416     5 0.00140 Preprocessor1_Model01\n 3     1    17 roc_auc     binary     0.689      5 0.00889 Preprocessor1_Model01\n 4     1    32 accuracy    binary     0.955      5 0.00162 Preprocessor1_Model02\n 5     1    32 brier_class binary     0.0416     5 0.00139 Preprocessor1_Model02\n 6     1    32 roc_auc     binary     0.688      5 0.00810 Preprocessor1_Model02\n 7     2     5 accuracy    binary     0.955      5 0.00157 Preprocessor1_Model03\n 8     2     5 brier_class binary     0.0415     5 0.00132 Preprocessor1_Model03\n 9     2     5 roc_auc     binary     0.688      5 0.0113  Preprocessor1_Model03\n10     3    21 accuracy    binary     0.955      5 0.00162 Preprocessor1_Model04\n# â„¹ 23 more rows"
  },
  {
    "objectID": "models/random-forest.html#visualize-the-metrics",
    "href": "models/random-forest.html#visualize-the-metrics",
    "title": "Random Forest",
    "section": "",
    "text": "autoplot(ranger_tune)"
  },
  {
    "objectID": "models/random-forest.html#choosing-the-best-hyperparameters",
    "href": "models/random-forest.html#choosing-the-best-hyperparameters",
    "title": "Random Forest",
    "section": "",
    "text": "best_weapon_carrying_forest &lt;- select_best(ranger_tune, metric = \"roc_auc\")\nbest_weapon_carrying_forest\n\n# A tibble: 1 Ã— 3\n   mtry min_n .config              \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;                \n1     1    17 Preprocessor1_Model01\n\n# cost_complexity = 1e-10; This is extremely small, meaning almost no penalty is applied for having a more complex tree. OVERFITTING"
  },
  {
    "objectID": "models/random-forest.html#finalize-the-workflow",
    "href": "models/random-forest.html#finalize-the-workflow",
    "title": "Random Forest",
    "section": "",
    "text": "carry_weapon_final_workflow_forest &lt;-\n  finalize_workflow(ranger_workflow, best_weapon_carrying_forest)\ncarry_weapon_final_workflow_forest\n\nâ•â• Workflow â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nPreprocessor: Recipe\nModel: rand_forest()\n\nâ”€â”€ Preprocessor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n3 Recipe Steps\n\nâ€¢ step_impute_mode()\nâ€¢ step_impute_mean()\nâ€¢ step_dummy()\n\nâ”€â”€ Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = 1\n  trees = 100\n  min_n = 17\n\nEngine-Specific Arguments:\n  importance = permutation\n\nComputational engine: ranger"
  },
  {
    "objectID": "models/random-forest.html#fit-the-forest",
    "href": "models/random-forest.html#fit-the-forest",
    "title": "Random Forest",
    "section": "",
    "text": "carry_weapon_fit_forest &lt;- fit(carry_weapon_final_workflow_forest, \n                               weapon_train)\ncarry_weapon_fit_forest\n\nsaveRDS(carry_weapon_fit_forest, here(\"models\",\"model_outputs\", \"forest_fit.rds\"))"
  },
  {
    "objectID": "models/random-forest.html#predictions-review-fit-on-the-training-data",
    "href": "models/random-forest.html#predictions-review-fit-on-the-training-data",
    "title": "Random Forest",
    "section": "",
    "text": "weapon_pred_forest &lt;-\n  augment(carry_weapon_fit_forest, weapon_train) |&gt;\n  select(WeaponCarryingSchool, .pred_class, .pred_1, .pred_0)\nweapon_pred_forest\n\n# A tibble: 11,022 Ã— 4\n   WeaponCarryingSchool .pred_class .pred_1 .pred_0\n   &lt;fct&gt;                &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;\n 1 0                    0            0.0470   0.953\n 2 0                    0            0.0328   0.967\n 3 0                    0            0.105    0.895\n 4 0                    0            0.0470   0.953\n 5 0                    0            0.0321   0.968\n 6 0                    0            0.0321   0.968\n 7 0                    0            0.0466   0.953\n 8 0                    0            0.0470   0.953\n 9 0                    0            0.0321   0.968\n10 0                    0            0.0669   0.933\n# â„¹ 11,012 more rows"
  },
  {
    "objectID": "models/random-forest.html#roc-graph",
    "href": "models/random-forest.html#roc-graph",
    "title": "Random Forest",
    "section": "",
    "text": "roc_plot_training_forest &lt;- \n  weapon_pred_forest |&gt; \n  roc_curve(truth = WeaponCarryingSchool, \n           .pred_0) |&gt; \n  autoplot()\nroc_plot_training_forest\n\nsaveRDS(roc_plot_training_forest, here(\"models\",\"roc_graphs\", \"forest.rds\"))"
  }
]